{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Topics in Information Theory and Machine Learning\n",
    "Computing entropies, cross-entropies, and the Kullback-Leibler divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programs from the book: [_Python for Natural Language Processing_](https://link.springer.com/book/9783031575488)\n",
    "\n",
    "__Author__: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from collections import Counter\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CORPUS = '../datasets/'\n",
    "\n",
    "# Computation of entropy with file\n",
    "salammbo_f = PATH_CORPUS + 'salammbo_chapters/salammbo_wikisource.txt'\n",
    "\n",
    "# Computation of cross-entropies with files P and M\n",
    "FILES_P = ['salammbo_chapters/salammbo_train_wikisource.txt',\n",
    "           'salammbo_chapters/salammbo_ch15.txt',\n",
    "           'modern_classics/notredame.txt',\n",
    "           'modern_classics/1984.txt']\n",
    "FILE_M = 'salammbo_chapters/salammbo_train_wikisource.txt'\n",
    "\n",
    "files_p = [PATH_CORPUS + file for file in FILES_P]\n",
    "file_m = PATH_CORPUS + FILE_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Processing \n",
    "Functions to normalize the corpus and count the frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(corpus: str,\n",
    "              upper: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Normalizes the text to ease the counts\n",
    "    Normalizes the blanks\n",
    "    Then removes all the chars below ASCII code 32\n",
    "    :param corpus:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Comment the next line to have the results from the 2014 edition\n",
    "    corpus = re.sub(r'\\s', ' ', corpus)\n",
    "    corpus = re.sub(r'[\\x00-\\x1F]', '', corpus)\n",
    "    if upper:\n",
    "        corpus = corpus.upper()\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def rel_freqs(corpus: str) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes the relative frequencies of the chars in a corpus\n",
    "    \"\"\"\n",
    "    counts = Counter(corpus)\n",
    "    total = counts.total()\n",
    "    return {key: val/total\n",
    "            for key, val in counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies of characters. Letters set in uppercase\n",
      "  103496\n",
      "! 939\n",
      "' 5992\n",
      "( 21\n",
      ") 21\n",
      ", 9643\n",
      "- 1518\n",
      ". 4584\n",
      ": 363\n",
      "; 1765\n",
      "? 178\n",
      "A 42439\n",
      "B 5757\n",
      "C 14202\n",
      "D 18907\n",
      "E 71186\n",
      "F 4993\n",
      "G 5148\n",
      "H 5293\n",
      "I 33627\n",
      "J 1220\n",
      "K 92\n",
      "L 30960\n",
      "M 13090\n",
      "N 32911\n",
      "O 22647\n",
      "P 13161\n",
      "Q 3964\n",
      "R 33555\n",
      "S 46753\n",
      "T 35084\n",
      "U 29268\n",
      "V 6916\n",
      "W 1\n",
      "X 2206\n",
      "Y 1232\n",
      "Z 413\n",
      "« 563\n",
      "» 559\n",
      "À 1884\n",
      "Â 605\n",
      "Æ 9\n",
      "Ç 452\n",
      "È 2002\n",
      "É 7709\n",
      "Ê 898\n",
      "Ë 6\n",
      "Î 277\n",
      "Ï 66\n",
      "Ô 397\n",
      "Ù 179\n",
      "Û 213\n",
      "Œ 96\n",
      "Total chars: 593314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_s = normalize(open(salammbo_f).read()).strip()\n",
    "\n",
    "chars_s_upper = Counter(text_s.upper())\n",
    "print('Frequencies of characters. Letters set in uppercase')\n",
    "total_chars = 0\n",
    "for char in sorted(chars_s_upper):\n",
    "    print(char, chars_s_upper[char])\n",
    "    if re.search(r'[\\p{L} ]', char):\n",
    "        total_chars += chars_s_upper[char]\n",
    "print('Total chars:', total_chars)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "We define functions to compute the entropy and cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(rel_freqs: dict[str, float]) -> float:\n",
    "    entropy = 0.0\n",
    "    for char in rel_freqs:\n",
    "        entropy -= rel_freqs[char] * log2(rel_freqs[char])\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def cross_entropy(rel_frequency_p: dict[str, float],\n",
    "                  rel_frequency_m: dict[str, float]) -> float:\n",
    "    cross_entropy = 0.0\n",
    "    for char in rel_frequency_p:\n",
    "        if rel_frequency_m.get(char, 0.0) != 0.0:\n",
    "            cross_entropy -= rel_frequency_p[char] * \\\n",
    "                log2(rel_frequency_m[char])\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the entropy of our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies of characters\n",
      "  103496\n",
      "! 939\n",
      "' 5992\n",
      "( 21\n",
      ") 21\n",
      ", 9643\n",
      "- 1518\n",
      ". 4584\n",
      ": 363\n",
      "; 1765\n",
      "? 178\n",
      "A 589\n",
      "B 389\n",
      "C 807\n",
      "D 486\n",
      "E 525\n",
      "F 15\n",
      "G 180\n",
      "H 449\n",
      "I 751\n",
      "J 93\n",
      "K 53\n",
      "L 993\n",
      "M 806\n",
      "N 226\n",
      "O 281\n",
      "P 345\n",
      "Q 177\n",
      "R 143\n",
      "S 812\n",
      "T 321\n",
      "U 178\n",
      "V 53\n",
      "X 2\n",
      "Y 3\n",
      "Z 48\n",
      "a 41850\n",
      "b 5368\n",
      "c 13395\n",
      "d 18421\n",
      "e 70661\n",
      "f 4978\n",
      "g 4968\n",
      "h 4844\n",
      "i 32876\n",
      "j 1127\n",
      "k 39\n",
      "l 29967\n",
      "m 12284\n",
      "n 32685\n",
      "o 22366\n",
      "p 12816\n",
      "q 3787\n",
      "r 33412\n",
      "s 45941\n",
      "t 34763\n",
      "u 29090\n",
      "v 6863\n",
      "w 1\n",
      "x 2204\n",
      "y 1229\n",
      "z 365\n",
      "« 563\n",
      "» 559\n",
      "À 1\n",
      "Ç 4\n",
      "à 1883\n",
      "â 605\n",
      "æ 9\n",
      "ç 448\n",
      "è 2002\n",
      "é 7709\n",
      "ê 898\n",
      "ë 6\n",
      "î 277\n",
      "ï 66\n",
      "ô 397\n",
      "ù 179\n",
      "û 213\n",
      "œ 96\n",
      "\n",
      "Entropy Salammbô: 4.370305083521603\n"
     ]
    }
   ],
   "source": [
    "print('Frequencies of characters')\n",
    "chars_s = Counter(text_s)\n",
    "for char in sorted(chars_s):\n",
    "    print(char, chars_s[char])\n",
    "print()\n",
    "\n",
    "rel_frequency_s = rel_freqs(text_s)\n",
    "entropy_s = entropy(rel_frequency_s)\n",
    "print('Entropy Salammbô:', entropy_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross entropies of the different texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropies\n",
      "H(P)    H(M)    H(P, M) D(P||M)\n",
      "4.37168 4.37168 4.37168 0.00000\n",
      "4.31338 4.37168 4.32544 0.01206\n",
      "4.42285 4.37168 4.44187 0.01902\n",
      "4.34982 4.37168 4.79617 0.44635\n"
     ]
    }
   ],
   "source": [
    "print('Cross-entropies')\n",
    "print(\"{:7} {:7} {:7} {:7}\".format('H(P)', 'H(M)', 'H(P, M)', 'D(P||M)'))\n",
    "for file_p in files_p:\n",
    "    text_p = normalize(open(file_p).read().strip())\n",
    "    text_m = normalize(open(file_m).read().strip())\n",
    "\n",
    "    rel_frequency_p = rel_freqs(text_p)\n",
    "    rel_frequency_m = rel_freqs(text_m)\n",
    "\n",
    "    entropy_p = entropy(rel_frequency_p)\n",
    "    entropy_m = entropy(rel_frequency_m)\n",
    "    cross_entropy_v = cross_entropy(rel_frequency_p, rel_frequency_m)\n",
    "    divergence = - entropy_p + cross_entropy_v\n",
    "    print(\"{:6.5f} {:6.5f} {:6.5f} {:6.5f}\".format(entropy_p, entropy_m,\n",
    "                                                   cross_entropy_v, divergence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the cross-perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-perplexity\n",
      "H(P)   H(M)   H(P, M)\n",
      "20.70 20.70 20.70\n",
      "19.88 20.70 20.05\n",
      "21.45 20.70 21.73\n",
      "20.39 20.70 27.78\n"
     ]
    }
   ],
   "source": [
    "print('Cross-perplexity')\n",
    "print(\"{:6} {:6} {:6}\".format('H(P)', 'H(M)', 'H(P, M)'))\n",
    "for file_p in files_p:\n",
    "    text_p = normalize(open(file_p).read().strip())\n",
    "    text_m = normalize(open(file_m).read().strip())\n",
    "\n",
    "    rel_frequency_p = rel_freqs(text_p)\n",
    "    rel_frequency_m = rel_freqs(text_m)\n",
    "\n",
    "    entropy_p = entropy(rel_frequency_p)\n",
    "    entropy_m = entropy(rel_frequency_m)\n",
    "    cross_entropy_v = cross_entropy(rel_frequency_p, rel_frequency_m)\n",
    "    print(\"{:4.2f} {:4.2f} {:4.2f}\".format(2**entropy_p, 2**entropy_m,\n",
    "                                           2**cross_entropy_v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
